{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc048e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from Parser import Parser\n",
    "import util\n",
    "from tfidf import *\n",
    "import glob, os\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "from __future__ import division, unicode_literals\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "class VectorSpace:\n",
    "    \"\"\" A algebraic model for representing text documents as vectors of identifiers. \n",
    "    A document is represented as a vector. Each dimension of the vector corresponds to a \n",
    "    separate term. If a term occurs in the document, then the value in the vector is non-zero.\n",
    "    \"\"\"\n",
    "\n",
    "    #Collection of document term vectors\n",
    "    documentVectors = []\n",
    "\n",
    "    #Mapping of vector index to keyword\n",
    "    vectorKeywordIndex=[]\n",
    "\n",
    "    #Tidies terms\n",
    "    parser=None\n",
    "    \n",
    "    def __init__(self, documents=[], vectorMode = 'tf'):\n",
    "        self.documentVectors=[]\n",
    "        self.parser = Parser()\n",
    "        self.BlobList = self.getBlobList(documents)\n",
    "        self.vectorMode = vectorMode\n",
    "        if(len(documents)>0):\n",
    "            self.build(documents)\n",
    "    \n",
    "    def getBlobList(self, documents): \n",
    "        bloblist = []\n",
    "        for doc in documents:\n",
    "            wordList = self.parser.tokenise(doc)\n",
    "            wordList = self.parser.removeStopWords(wordList)\n",
    "            bloblist.append(tb(\" \".join(wordList)))\n",
    "        return bloblist\n",
    "            \n",
    "    def build(self,documents):\n",
    "        \"\"\" Create the vector space for the passed document strings \"\"\"\n",
    "        self.vectorKeywordIndex = self.getVectorKeywordIndex(documents)\n",
    "        self.documentVectors = [self.makeVector(document, self.vectorMode) for document in tqdm(documents)]\n",
    "\n",
    "        #print(self.vectorKeywordIndex)\n",
    "        #print(self.documentVectors)\n",
    "\n",
    "\n",
    "    def getVectorKeywordIndex(self, documentList):\n",
    "        \"\"\" create the keyword associated to the position of the elements within the document vectors \"\"\"\n",
    "\n",
    "        #Mapped documents into a single word string\t\n",
    "        vocabularyString = \" \".join(documentList)\n",
    "\n",
    "        vocabularyList = self.parser.tokenise(vocabularyString)\n",
    "        #Remove common words which have no search value\n",
    "        vocabularyList = self.parser.removeStopWords(vocabularyList)\n",
    "        uniqueVocabularyList = util.removeDuplicates(vocabularyList)\n",
    "        \n",
    "        vectorIndex={}\n",
    "        offset=0\n",
    "        #Associate a position with the keywords which maps to the dimension on the vector used to represent this word\n",
    "        for word in uniqueVocabularyList:\n",
    "            vectorIndex[word]=offset\n",
    "            offset+=1\n",
    "        return vectorIndex  #(keyword:position)\n",
    "\n",
    "\n",
    "    def makeVector(self, wordString, mode):\n",
    "        \"\"\" @pre: unique(vectorIndex) \"\"\"\n",
    "        #Initialise vector with 0's\n",
    "        vector = [0] * len(self.vectorKeywordIndex)\n",
    "        wordList = self.parser.tokenise(wordString)\n",
    "        wordList = self.parser.removeStopWords(wordList)\n",
    "        tbString = tb(\" \".join(wordList))\n",
    "        #print(wordList)\n",
    "        if mode == 'tf':\n",
    "            for word in list(set(wordList)):\n",
    "                vector[self.vectorKeywordIndex[word]] = tf(word, tbString) #Use simple Term Count Model\n",
    "            return vector \n",
    "        \n",
    "        if mode == 'tf-idf':\n",
    "            #print('bloblist:', self.BlobList)\n",
    "            for word in list(set(wordList)):\n",
    "                #print('word',word)\n",
    "                vector[self.vectorKeywordIndex[word]] =  tfidf(word, tbString , self.BlobList) \n",
    "                #print('word:',word, 'idf:', idf(word, self.BlobList),  )\n",
    "                #print('word:', word, 'tf:', tf(word, tbString))\n",
    "            return vector\n",
    "        \n",
    "    def buildQueryVector(self, termList):\n",
    "        \"\"\" convert query string into a term vector \"\"\"\n",
    "        #print(termList)\n",
    "        #print(self.vectorMode)\n",
    "        query = self.makeVector(\" \".join(termList), self.vectorMode)\n",
    "        return query\n",
    "\n",
    "    def related(self,documentId):\n",
    "        \"\"\" find documents that are related to the document indexed by passed Id within the document Vectors\"\"\"\n",
    "        ratings = [util.cosine(self.documentVectors[documentId], documentVector) for documentVector in self.documentVectors]\n",
    "        #ratings.sort(reverse=True)\n",
    "        return ratings\n",
    "    \n",
    "    def search(self,searchList, mode = 'cos'):\n",
    "        \"\"\" search for documents that match based on a list of terms \"\"\"\n",
    "        #print(searchList)\n",
    "        if type(searchList[0]) == str:\n",
    "            queryVector = self.buildQueryVector(searchList)\n",
    "            #print(queryVector)\n",
    "        else:\n",
    "            queryVector = searchList\n",
    "        \n",
    "        if mode == 'cos':\n",
    "            ratings = [util.cosine(queryVector, documentVector) for documentVector in tqdm(self.documentVectors)]\n",
    "        #ratings.sort(reverse=True)\n",
    "            return ratings\n",
    "        if mode == 'eucli':\n",
    "            ratings = [util.Euclidean(queryVector, documentVector) for documentVector in tqdm(self.documentVectors)]\n",
    "            return ratings\n",
    "\n",
    "    def printresult(self,searchlist, files,n, mode='cos'):\n",
    "        scoreList = self.search(searchlist, mode = mode)\n",
    "        if self.vectorMode == 'tf' and mode == 'cos':\n",
    "            print('Term Frequency (TF) Weighting + Cosine Similarity\\n')\n",
    "        elif self.vectorMode == 'tf' and mode == 'eucli':\n",
    "            print('Term Frequency (TF) Weighting + Euclidean Distance\\n')\n",
    "        elif self.vectorMode == 'tf-idf' and mode == 'cos':\n",
    "            print('TF-IDF Weighting + Cosine Similarity\\n')\n",
    "        elif self.vectorMode == 'tf-idf' and mode == 'eucli':\n",
    "            print('TF-IDF Weighting + Euclidean Distance\\n')\n",
    "        print( 'NewsID' ,'         ','score')\n",
    "        print('----------','     ','--------')\n",
    "        for i in np.flip(np.argsort(scoreList))[:n]:\n",
    "            print(files[i],'     ' ,scoreList[i])\n",
    "        return np.flip(np.argsort(scoreList))[:n]\n",
    "            \n",
    "    def getFeedbackVector(self, searchList, top10results ,mode = 'cos'):\n",
    "        queryVector = self.buildQueryVector(searchList)\n",
    "        feedbackVector = self.buildQueryVector(top10results)\n",
    "        queryArray = np.array(queryVector)\n",
    "        feedbackArray = np.array(feedbackVector)\n",
    "        newQueryVector = list(queryArray + 0.5 * feedbackArray)\n",
    "        return newQueryVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21bd51c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:10<00:00, 667.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7034/7034 [01:02<00:00, 111.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency (TF) Weighting + Cosine Similarity\n",
      "\n",
      "NewsID           score\n",
      "----------       --------\n",
      "News123256       0.516398\n",
      "News119356       0.516398\n",
      "News108578       0.468521\n",
      "News120265       0.468521\n",
      "News103117       0.428746\n",
      "News115594       0.426401\n",
      "News112667       0.400892\n",
      "News122919       0.40032\n",
      "News111959       0.395285\n",
      "News115859       0.395285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:25<00:00, 271.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency (TF) Weighting + Euclidean Distance\n",
      "\n",
      "NewsID           score\n",
      "----------       --------\n",
      "News108482       0.67082\n",
      "News110871       0.67082\n",
      "News110141       0.67082\n",
      "News111696       0.67082\n",
      "News108964       0.67082\n",
      "News108940       0.67082\n",
      "News107883       0.661438\n",
      "News107832       0.645497\n",
      "News108270       0.645497\n",
      "News110401       0.645497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    documents = []\n",
    "    files = []\n",
    "    for file in os.listdir(\"./EnglishNews/EnglishNews\"):\n",
    "        if file.endswith(\".txt\"):\n",
    "            filename = os.path.join(\"./EnglishNews/EnglishNews\", file)\n",
    "            files.append(file[:-4])\n",
    "            with open(filename, encoding=\"utf-8\") as f:\n",
    "                lines = f.readlines()\n",
    "                doc = ' '.join(lines)\n",
    "                doc1 = doc.replace(\"\\n\", \"\")\n",
    "                documents.append(doc1)\n",
    "                \n",
    "    query = [\"Trump Biden Taiwan China\"]\n",
    "    \n",
    "    vectorSpace_tf = VectorSpace(documents, 'tf')\n",
    "    \n",
    "    rank_cos = vectorSpace_tf.printresult(query,files,10,'cos')  #60% 前30: 100% \n",
    "    rank_euc = vectorSpace_tf.printresult(query,files, 10,mode = 'eucli')  #50% 前30: 80%\n",
    "    '''\n",
    "    vectorSpace_tfidf = VectorSpace(documents,'tf-idf')\n",
    "    \n",
    "    rank_cos_tfidf = vectorSpace_tfidf.printresult(query,files, 10,'cos')#70% #前30個100%\n",
    "    rank_euc_tfidf = vectorSpace_tfidf.printresult(query,files, 10,'eucli')#40% #前30個40%\n",
    "    '''\n",
    "\n",
    "    # Q2\n",
    "    '''\n",
    "    feedBack = []\n",
    "    for i in rank_cos_tfidf[:10]:\n",
    "        feedBack.append(documents[i])\n",
    "        feedback = [\" \".join(feedBack)]\n",
    "\n",
    "    print('TF-IDF Weighting + Cosine Similarity') # 70%\n",
    "    newquery = vectorSpace_tfidf.getFeedbackVector(query, feedback, 'cos')\n",
    "    vectorSpace_tfidf.printresult(newquery,files, 10,'cos')    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e5184b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6902, 5093, 2128, 5369,  750, 4078, 3247, 6565, 3037, 4152],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_cos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfca94dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Weighting + Cosine Similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:55<00:00, 127.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency (TF) Weighting + Cosine Similarity\n",
      "\n",
      "NewsID           score\n",
      "----------       --------\n",
      "News123256       0.564763\n",
      "News119356       0.564763\n",
      "News120265       0.511991\n",
      "News108578       0.511991\n",
      "News103117       0.454892\n",
      "News115594       0.454539\n",
      "News115859       0.446891\n",
      "News111959       0.446891\n",
      "News101763       0.446891\n",
      "News119746       0.446891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6902, 5093, 5369, 2128,  750, 4078, 4152, 3037,  425, 5205],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a62d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:07<00:00, 902.13it/s]\n"
     ]
    }
   ],
   "source": [
    "cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a96060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:53<00:00, 130.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency (TF) Weighting + Cosine Similarity\n",
      "document: News119356 score: 0.5163977794943222\n",
      "document: News123256 score: 0.5163977794943222\n",
      "document: News120265 score: 0.4685212856658182\n",
      "document: News108578 score: 0.4685212856658182\n",
      "document: News103117 score: 0.42874646285627205\n",
      "document: News115594 score: 0.42640143271122083\n",
      "document: News112667 score: 0.4008918628686366\n",
      "document: News122919 score: 0.4003203845127178\n",
      "document: News111959 score: 0.39528470752104733\n",
      "document: News115859 score: 0.39528470752104733\n",
      "document: News119746 score: 0.39528470752104733\n",
      "document: News101763 score: 0.39528470752104733\n",
      "document: News120085 score: 0.39043440472151514\n",
      "document: News104498 score: 0.39043440472151514\n",
      "document: News110775 score: 0.39043440472151514\n",
      "document: News112298 score: 0.39043440472151514\n",
      "document: News122462 score: 0.39043440472151514\n",
      "document: News114963 score: 0.3857583749052298\n",
      "document: News122750 score: 0.3857583749052298\n",
      "document: News107163 score: 0.3857583749052298\n",
      "document: News115598 score: 0.3768891807222046\n",
      "document: News111698 score: 0.3768891807222046\n",
      "document: News123385 score: 0.3768891807222046\n",
      "document: News119485 score: 0.3768891807222046\n",
      "document: News106911 score: 0.372677996249965\n",
      "document: News119460 score: 0.37267799624996495\n",
      "document: News115573 score: 0.37267799624996495\n",
      "document: News103873 score: 0.37267799624996495\n",
      "document: News107773 score: 0.37267799624996495\n",
      "document: News123360 score: 0.37267799624996495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:21<00:00, 324.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency (TF) Weighting + Euclidean Distance\n",
      "document: News108482 score: 0.6708203932499369\n",
      "document: News110871 score: 0.6708203932499369\n",
      "document: News108964 score: 0.6708203932499369\n",
      "document: News108940 score: 0.6708203932499369\n",
      "document: News110141 score: 0.6708203932499369\n",
      "document: News111696 score: 0.6708203932499369\n",
      "document: News107883 score: 0.6614378277661477\n",
      "document: News107832 score: 0.6454972243679028\n",
      "document: News110401 score: 0.6454972243679028\n",
      "document: News108270 score: 0.6454972243679028\n",
      "document: News110747 score: 0.6267831705280087\n",
      "document: News110223 score: 0.6267831705280087\n",
      "document: News109912 score: 0.6267831705280087\n",
      "document: News110329 score: 0.6267831705280087\n",
      "document: News110497 score: 0.6267831705280087\n",
      "document: News111420 score: 0.6236095644623235\n",
      "document: News110833 score: 0.6236095644623235\n",
      "document: News108024 score: 0.6236095644623235\n",
      "document: News109276 score: 0.6123724356957945\n",
      "document: News107804 score: 0.6123724356957945\n",
      "document: News122771 score: 0.6123724356957945\n",
      "document: News108334 score: 0.6123724356957945\n",
      "document: News109013 score: 0.6123724356957945\n",
      "document: News109562 score: 0.6115283657760777\n",
      "document: News109622 score: 0.6102859818083951\n",
      "document: News111034 score: 0.6102859818083951\n",
      "document: News110033 score: 0.6102859818083951\n",
      "document: News109017 score: 0.6102859818083951\n",
      "document: News109808 score: 0.6102859818083951\n",
      "document: News109402 score: 0.608276253029822\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print('Term Frequency (TF) Weighting + Euclidean Distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfaf6a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7034/7034 [18:41<00:00,  6.27it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55429a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:56<00:00, 124.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Weighting + Cosine Similarity\n",
      "document: News103134 score: 0.47354915840176326\n",
      "document: News103767 score: 0.4560496763154008\n",
      "document: News116613 score: 0.4110554885255448\n",
      "document: News104913 score: 0.4110554885255448\n",
      "document: News108813 score: 0.4110554885255448\n",
      "document: News104914 score: 0.38949623702525554\n",
      "document: News112714 score: 0.38949623702525554\n",
      "document: News101014 score: 0.38949623702525554\n",
      "document: News116634 score: 0.38593749188632803\n",
      "document: News103728 score: 0.3649292024732102\n",
      "document: News103602 score: 0.32887988817071073\n",
      "document: News120085 score: 0.3149122389640781\n",
      "document: News104498 score: 0.3149122389640781\n",
      "document: News112298 score: 0.3149122389640781\n",
      "document: News110040 score: 0.3133693689239125\n",
      "document: News110441 score: 0.3111255372629767\n",
      "document: News106640 score: 0.3080687882294075\n",
      "document: News100757 score: 0.29709045391611844\n",
      "document: News110804 score: 0.29511422948403626\n",
      "document: News121995 score: 0.29225581198231654\n",
      "document: News118108 score: 0.29225581198231654\n",
      "document: News107830 score: 0.2876847733877949\n",
      "document: News105080 score: 0.2731988825469898\n",
      "document: News111015 score: 0.26557133629101504\n",
      "document: News101323 score: 0.2614508726801889\n",
      "document: News103117 score: 0.2572204467425838\n",
      "document: News103214 score: 0.256440764245066\n",
      "document: News101070 score: 0.22513438697757518\n",
      "document: News120265 score: 0.21909792943439113\n",
      "document: News108578 score: 0.21909792943439113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:23<00:00, 303.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Weighting + Euclidean Distance\n",
      "document: News111696 score: 3.1738412094930877\n",
      "document: News108964 score: 3.090312939538556\n",
      "document: News107883 score: 3.0655439111104896\n",
      "document: News110141 score: 3.0640754366202367\n",
      "document: News122771 score: 3.0143726040179266\n",
      "document: News110747 score: 3.009559318414031\n",
      "document: News108482 score: 2.9345996967448014\n",
      "document: News108940 score: 2.9248801263833597\n",
      "document: News108270 score: 2.874122470395115\n",
      "document: News110871 score: 2.8523192991552713\n",
      "document: News107804 score: 2.829682742565021\n",
      "document: News107832 score: 2.8115392443751284\n",
      "document: News110833 score: 2.746581890623016\n",
      "document: News110401 score: 2.744118697256618\n",
      "document: News123304 score: 2.73874948545406\n",
      "document: News109473 score: 2.730692961761022\n",
      "document: News110223 score: 2.7254989764094484\n",
      "document: News111034 score: 2.6819244734119745\n",
      "document: News109622 score: 2.66270152162418\n",
      "document: News123024 score: 2.6601117436200727\n",
      "document: News109912 score: 2.636160698408388\n",
      "document: News108024 score: 2.6299012784937372\n",
      "document: News110579 score: 2.6173442014973767\n",
      "document: News122495 score: 2.615172009658899\n",
      "document: News108062 score: 2.6111662541354987\n",
      "document: News109808 score: 2.6019309130400594\n",
      "document: News119516 score: 2.5955984910339813\n",
      "document: News108334 score: 2.5714210285031593\n",
      "document: News110497 score: 2.55094239130443\n",
      "document: News110029 score: 2.550184663472354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c156e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "946e6dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Weighting + Cosine Similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7034/7034 [01:20<00:00, 87.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: News103134 score: 0.5197886511286802\n",
      "document: News104913 score: 0.5124974838557128\n",
      "document: News108813 score: 0.5124974838557128\n",
      "document: News116613 score: 0.5124974838557128\n",
      "document: News101014 score: 0.4989410742564866\n",
      "document: News112714 score: 0.4989410742564866\n",
      "document: News104914 score: 0.4989410742564866\n",
      "document: News103767 score: 0.49212543366673545\n",
      "document: News116634 score: 0.4379371826487922\n",
      "document: News103728 score: 0.3943061599242882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 754, 1168, 2183, 4360,  240, 3259, 1169,  900, 4368,  889],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daea5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c92602a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37688ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f35890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d9a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b0f0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "22152a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: nan document: I haven't got a hat.\n",
      "score: nan document: Dogs and cats make good pets.\n",
      "score: nan document: A cat is a fine pet ponies.\n",
      "score: nan document: The cat cat in the hat disabled\n",
      "score: 1.2345525572306575 document: Dogs and cats make good pets.\n",
      "score: 1.0216002166437488 document: A cat is a fine pet ponies.\n",
      "score: 0.7504758415354574 document: The cat cat in the hat disabled\n",
      "score: 0.28768207245178085 document: I haven't got a hat.\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "\n",
    "documents = [\"The cat cat in the hat disabled\",\n",
    "                 \"A cat is a fine pet ponies.\",\n",
    "                 \"Dogs and cats make good pets.\",\n",
    "                 \"I haven't got a hat.\"]\n",
    "\n",
    "vectorSpace = VectorSpace(documents, 'tf-idf')  # vectorSpace(documents, vectorMode = 'tf' or 'tf-idf') (default is 'tf')\n",
    "\n",
    "\n",
    "#print(vectorSpace.vectorKeywordIndex)\n",
    "\n",
    "#print(vectorSpace.documentVectors)\n",
    "\n",
    "#print(vectorSpace.related(1))\n",
    "\n",
    "#print(vectorSpace.search([\"cat\"]))   \n",
    "\n",
    "vectorSpace.printresult([\"cat\"])\n",
    "vectorSpace.printresult([\"cat\"], mode = 'eucli')  # mode = 'cos' or 'eucli' (default is 'cos')\n",
    "\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179dc26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
