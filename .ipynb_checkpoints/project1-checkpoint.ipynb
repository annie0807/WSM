{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ed402e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\anny_\\anaconda3\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\anny_\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efc048e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from Parser import Parser\n",
    "import util\n",
    "from tfidf import *\n",
    "import glob, os\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from __future__ import division, unicode_literals\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "class VectorSpace:\n",
    "    \"\"\" A algebraic model for representing text documents as vectors of identifiers. \n",
    "    A document is represented as a vector. Each dimension of the vector corresponds to a \n",
    "    separate term. If a term occurs in the document, then the value in the vector is non-zero.\n",
    "    \"\"\"\n",
    "\n",
    "    #Collection of document term vectors\n",
    "    documentVectors = []\n",
    "\n",
    "    #Mapping of vector index to keyword\n",
    "    vectorKeywordIndex=[]\n",
    "\n",
    "    #Tidies terms\n",
    "    parser=None\n",
    "    \n",
    "    def __init__(self, documents=[], vectorMode = 'tf'):\n",
    "        self.documentVectors=[]\n",
    "        self.parser = Parser()\n",
    "        self.BlobList = self.getBlobList(documents)\n",
    "        self.vectorMode = vectorMode\n",
    "        if(len(documents)>0):\n",
    "            self.build(documents)\n",
    "    \n",
    "    def getBlobList(self, documents): \n",
    "        bloblist = []\n",
    "        for doc in documents:\n",
    "            wordList = self.parser.tokenise(doc)\n",
    "            wordList = self.parser.removeStopWords(wordList)\n",
    "            bloblist.append(tb(\" \".join(wordList)))\n",
    "        return bloblist\n",
    "            \n",
    "    def build(self,documents):\n",
    "        \"\"\" Create the vector space for the passed document strings \"\"\"\n",
    "        self.vectorKeywordIndex = self.getVectorKeywordIndex(documents)\n",
    "        self.documentVectors = [self.makeVector(document, self.vectorMode) for document in tqdm(documents)]\n",
    "\n",
    "        #print(self.vectorKeywordIndex)\n",
    "        #print(self.documentVectors)\n",
    "\n",
    "\n",
    "    def getVectorKeywordIndex(self, documentList):\n",
    "        \"\"\" create the keyword associated to the position of the elements within the document vectors \"\"\"\n",
    "\n",
    "        #Mapped documents into a single word string\t\n",
    "        vocabularyString = \" \".join(documentList)\n",
    "\n",
    "        vocabularyList = self.parser.tokenise(vocabularyString)\n",
    "        #print(vocabularyList)\n",
    "        #print(vocabularyString)\n",
    "        #Remove common words which have no search value\n",
    "        vocabularyList = self.parser.removeStopWords(vocabularyList)\n",
    "        #print(vocabularyList)\n",
    "        uniqueVocabularyList = util.removeDuplicates(vocabularyList)\n",
    "        #print(uniqueVocabularyList)\n",
    "        vectorIndex={}\n",
    "        offset=0\n",
    "        #Associate a position with the keywords which maps to the dimension on the vector used to represent this word\n",
    "        for word in uniqueVocabularyList:\n",
    "            vectorIndex[word]=offset\n",
    "            offset+=1\n",
    "        return vectorIndex  #(keyword:position)\n",
    "\n",
    "\n",
    "    def makeVector(self, wordString, mode):\n",
    "        \"\"\" @pre: unique(vectorIndex) \"\"\"\n",
    "        #Initialise vector with 0's\n",
    "        vector = [0] * len(self.vectorKeywordIndex)\n",
    "        wordList = self.parser.tokenise(wordString)\n",
    "        wordList = self.parser.removeStopWords(wordList)\n",
    "        tbString = tb(\" \".join(wordList))\n",
    "        if mode == 'tf':\n",
    "            for word in list(set(wordList)):\n",
    "                vector[self.vectorKeywordIndex[word]] = tf(word, tbString) #Use simple Term Count Model\n",
    "            return vector \n",
    "        \n",
    "        if mode == 'tf-idf':\n",
    "            #print('bloblist:', self.BlobList)\n",
    "            for word in list(set(wordList)):\n",
    "                #print('word',word)\n",
    "                vector[self.vectorKeywordIndex[word]] =  tfidf(word, tbString , self.BlobList) \n",
    "                #print('word:',word, 'idf:', idf(word, self.BlobList),  )\n",
    "                #print('word:', word, 'tf:', tf(word, tbString))\n",
    "            return vector\n",
    "\n",
    "    def buildQueryVector(self, termList):\n",
    "        \"\"\" convert query string into a term vector \"\"\"\n",
    "        #print(termList)\n",
    "        #print(self.vectorMode)\n",
    "        query = self.makeVector(\" \".join(termList), self.vectorMode)\n",
    "        return query\n",
    "\n",
    "    def related(self,documentId):\n",
    "        \"\"\" find documents that are related to the document indexed by passed Id within the document Vectors\"\"\"\n",
    "        ratings = [util.cosine(self.documentVectors[documentId], documentVector) for documentVector in self.documentVectors]\n",
    "        #ratings.sort(reverse=True)\n",
    "        return ratings\n",
    "    \n",
    "    def search(self,searchList, mode = 'cos'):\n",
    "        \"\"\" search for documents that match based on a list of terms \"\"\"\n",
    "        #print(searchList)\n",
    "        queryVector = self.buildQueryVector(searchList)\n",
    "        #print(queryVector)\n",
    "        if mode == 'cos':\n",
    "            ratings = [util.cosine(queryVector, documentVector) for documentVector in tqdm(self.documentVectors)]\n",
    "        #ratings.sort(reverse=True)\n",
    "            return ratings\n",
    "        if mode == 'eucli':\n",
    "            ratings = [util.Euclidean(queryVector, documentVector) for documentVector in tqdm(self.documentVectors)]\n",
    "            return ratings\n",
    "\n",
    "    \n",
    "    def printresult(self,searchlist, files, mode='cos'):\n",
    "        scoreList = self.search(searchlist, mode = mode)\n",
    "        for i in np.flip(np.argsort(scoreList))[:10]:\n",
    "            print( 'NewsID:' , files[i],'score:', scoreList[i])\n",
    "        return scoreList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21bd51c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open(\"./EnglishNews/EnglishNews/News100012.txt\", encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    doc = ' '.join(lines)\n",
    "    doc1 = doc.replace(\"\\n\", \"\")\n",
    "\n",
    "print(doc1)\n",
    "'''\n",
    "\n",
    "documents = []\n",
    "files = []\n",
    "for file in os.listdir(\"./EnglishNews/EnglishNews\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        filename = os.path.join(\"./EnglishNews/EnglishNews\", file)\n",
    "        files.append(file[:-4])\n",
    "        with open(filename, encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            doc = ' '.join(lines)\n",
    "            doc1 = doc.replace(\"\\n\", \"\")\n",
    "            documents.append(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c09766a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:15<00:00, 464.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 7034/7034 [01:41<00:00, 69.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: News123256 score: 0.5163977794943223\n",
      "document: News119356 score: 0.5163977794943223\n",
      "document: News108578 score: 0.46852128566581813\n",
      "document: News120265 score: 0.46852128566581813\n",
      "document: News103117 score: 0.42874646285627205\n",
      "document: News115594 score: 0.42640143271122083\n",
      "document: News112667 score: 0.4008918628686366\n",
      "document: News122919 score: 0.4003203845127178\n",
      "document: News119746 score: 0.39528470752104733\n",
      "document: News111959 score: 0.39528470752104733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:36<00:00, 190.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: News111696 score: 0.6708203932499369\n",
      "document: News108940 score: 0.6708203932499369\n",
      "document: News110871 score: 0.6708203932499369\n",
      "document: News110141 score: 0.6708203932499369\n",
      "document: News108964 score: 0.6708203932499369\n",
      "document: News108482 score: 0.6708203932499369\n",
      "document: News107883 score: 0.6614378277661477\n",
      "document: News110401 score: 0.6454972243679028\n",
      "document: News108270 score: 0.6454972243679028\n",
      "document: News107832 score: 0.6454972243679028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vectorSpace_tf = VectorSpace(documents, 'tf')\n",
    "print('Term Frequency (TF) Weighting + Cosine Similarity', mode = 'cos') # 60%\n",
    "vectorSpace_tf.printresult([\"Trump Biden Taiwan China\"],files)\n",
    "print('Term Frequency (TF) Weighting + Euclidean Distance') #50%\n",
    "vectorSpace_tf.printresult([\"Trump Biden Taiwan China\"],files, mode = 'eucli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f90e94b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7034/7034 [36:59<00:00,  3.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 7034/7034 [02:43<00:00, 43.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: News103134 score: 0.47354915840176326\n",
      "document: News103767 score: 0.4560496763154007\n",
      "document: News116613 score: 0.4110554885255447\n",
      "document: News104913 score: 0.4110554885255447\n",
      "document: News108813 score: 0.4110554885255447\n",
      "document: News104914 score: 0.38949623702525554\n",
      "document: News112714 score: 0.38949623702525554\n",
      "document: News101014 score: 0.38949623702525554\n",
      "document: News116634 score: 0.385937491886328\n",
      "document: News103728 score: 0.36492920247321015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7034/7034 [01:05<00:00, 108.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: News111696 score: 3.1738412094930872\n",
      "document: News108964 score: 3.090312939538556\n",
      "document: News107883 score: 3.0655439111104896\n",
      "document: News110141 score: 3.0640754366202367\n",
      "document: News122771 score: 3.014372604017926\n",
      "document: News110747 score: 3.009559318414031\n",
      "document: News108482 score: 2.9345996967448014\n",
      "document: News108940 score: 2.9248801263833597\n",
      "document: News108270 score: 2.874122470395115\n",
      "document: News110871 score: 2.8523192991552713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vectorSpace_tfidf = VectorSpace(documents ,'tf-idf')\n",
    "print('TF-IDF Weighting + Cosine Similarity') # 70%\n",
    "vectorSpace_tfidf.printresult([\"Trump Biden Taiwan China\"],files)\n",
    "print('TF-IDF Weighting + Euclidean Distance') # 40%\n",
    "vectorSpace_tfidf.printresult([\"Trump Biden Taiwan China\"],files, mode = 'eucli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d9a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f138d5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "22152a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: nan document: I haven't got a hat.\n",
      "score: nan document: Dogs and cats make good pets.\n",
      "score: nan document: A cat is a fine pet ponies.\n",
      "score: nan document: The cat cat in the hat disabled\n",
      "score: 1.2345525572306575 document: Dogs and cats make good pets.\n",
      "score: 1.0216002166437488 document: A cat is a fine pet ponies.\n",
      "score: 0.7504758415354574 document: The cat cat in the hat disabled\n",
      "score: 0.28768207245178085 document: I haven't got a hat.\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "\n",
    "documents = [\"The cat cat in the hat disabled\",\n",
    "                 \"A cat is a fine pet ponies.\",\n",
    "                 \"Dogs and cats make good pets.\",\n",
    "                 \"I haven't got a hat.\"]\n",
    "\n",
    "vectorSpace = VectorSpace(documents, 'tf-idf')  # vectorSpace(documents, vectorMode = 'tf' or 'tf-idf') (default is 'tf')\n",
    "\n",
    "\n",
    "#print(vectorSpace.vectorKeywordIndex)\n",
    "\n",
    "#print(vectorSpace.documentVectors)\n",
    "\n",
    "#print(vectorSpace.related(1))\n",
    "\n",
    "#print(vectorSpace.search([\"cat\"]))   \n",
    "\n",
    "vectorSpace.printresult([\"cat\"])\n",
    "vectorSpace.printresult([\"cat\"], mode = 'eucli')  # mode = 'cos' or 'eucli' (default is 'cos')\n",
    "\n",
    "###################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
