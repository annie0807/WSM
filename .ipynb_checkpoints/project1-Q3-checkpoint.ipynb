{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efc048e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from Parser import Parser\n",
    "import util\n",
    "from tfidf import *\n",
    "import glob, os\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "from __future__ import division, unicode_literals\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "class VectorSpace:\n",
    "    \"\"\" A algebraic model for representing text documents as vectors of identifiers. \n",
    "    A document is represented as a vector. Each dimension of the vector corresponds to a \n",
    "    separate term. If a term occurs in the document, then the value in the vector is non-zero.\n",
    "    \"\"\"\n",
    "\n",
    "    #Collection of document term vectors\n",
    "    documentVectors = []\n",
    "\n",
    "    #Mapping of vector index to keyword\n",
    "    vectorKeywordIndex=[]\n",
    "\n",
    "    #Tidies terms\n",
    "    parser=None\n",
    "    \n",
    "    def __init__(self, documents=[], vectorMode = 'tf'):\n",
    "        self.documentVectors=[]\n",
    "        self.parser = Parser()\n",
    "        self.BlobList = self.getBlobList(documents)\n",
    "        self.vectorMode = vectorMode\n",
    "        if(len(documents)>0):\n",
    "            self.build(documents)\n",
    "    \n",
    "    def getBlobList(self, documents): \n",
    "        bloblist = []\n",
    "        for doc in documents:\n",
    "            wordList = self.parser.tokenise(doc)\n",
    "            wordList = self.parser.removeStopWords(wordList)\n",
    "            bloblist.append(tb(\" \".join(wordList)))\n",
    "        return bloblist\n",
    "            \n",
    "    def build(self,documents):\n",
    "        \"\"\" Create the vector space for the passed document strings \"\"\"\n",
    "        self.vectorKeywordIndex = self.getVectorKeywordIndex(documents)\n",
    "        self.documentVectors = [self.makeVector(document, self.vectorMode) for document in tqdm(documents)]\n",
    "\n",
    "    def getVectorKeywordIndex(self, documentList):\n",
    "        \"\"\" create the keyword associated to the position of the elements within the document vectors \"\"\"\n",
    "\n",
    "        #Mapped documents into a single word string\t\n",
    "        vocabularyString = \" \".join(documentList)\n",
    "\n",
    "        vocabularyList = self.parser.tokenise(vocabularyString) #斷詞\n",
    "        #Remove common words which have no search value\n",
    "        vocabularyList = self.parser.removeStopWords(vocabularyList) # 去掉stop words\n",
    "        uniqueVocabularyList = util.removeDuplicates(vocabularyList) # 去掉重複詞\n",
    "        \n",
    "        vectorIndex={}\n",
    "        offset=0\n",
    "        #Associate a position with the keywords which maps to the dimension on the vector used to represent this word\n",
    "        for word in uniqueVocabularyList:\n",
    "            vectorIndex[word]=offset\n",
    "            offset+=1\n",
    "        return vectorIndex  #(keyword:position)\n",
    "\n",
    "\n",
    "    def makeVector(self, wordString, mode):\n",
    "        \"\"\" @pre: unique(vectorIndex) \"\"\"\n",
    "        #Initialise vector with 0's\n",
    "        vector = [0] * len(self.vectorKeywordIndex)\n",
    "        wordList = self.parser.tokenise(wordString)\n",
    "        wordList = self.parser.removeStopWords(wordList)\n",
    "        tbString = tb(\" \".join(wordList))\n",
    "        if mode == 'tf':\n",
    "            for word in list(set(wordList)):\n",
    "                vector[self.vectorKeywordIndex[word]] = tf(word, tbString) #Use simple Term Count Model\n",
    "            return vector \n",
    "        \n",
    "        if mode == 'tf-idf':\n",
    "            #print('bloblist:', self.BlobList)\n",
    "            for word in list(set(wordList)):\n",
    "                vector[self.vectorKeywordIndex[word]] =  tfidf(word, tbString , self.BlobList) \n",
    "            return vector\n",
    "        \n",
    "    def buildQueryVector(self, termList):\n",
    "        \"\"\" convert query string into a term vector \"\"\"\n",
    "        query = self.makeVector(\" \".join(termList), self.vectorMode)\n",
    "        return query\n",
    "\n",
    "    def related(self,documentId):\n",
    "        \"\"\" find documents that are related to the document indexed by passed Id within the document Vectors\"\"\"\n",
    "        ratings = [util.cosine(self.documentVectors[documentId], documentVector) for documentVector in self.documentVectors]\n",
    "        #ratings.sort(reverse=True)\n",
    "        return ratings\n",
    "    \n",
    "    def search(self,searchList, mode = 'cos'):\n",
    "        \"\"\" search for documents that match based on a list of terms \"\"\"\n",
    "        if type(searchList[0]) == str:\n",
    "            queryVector = self.buildQueryVector(searchList)\n",
    "        else:\n",
    "            queryVector = searchList\n",
    "        \n",
    "        if mode == 'cos':\n",
    "            ratings = [util.cosine(queryVector, documentVector) for documentVector in tqdm(self.documentVectors)]\n",
    "        #ratings.sort(reverse=True)\n",
    "            return ratings\n",
    "        if mode == 'eucli':\n",
    "            ratings = [util.Euclidean(queryVector, documentVector) for documentVector in tqdm(self.documentVectors)]\n",
    "            return ratings\n",
    "\n",
    "    def printresult(self,searchlist, files,n,mode='cos'):\n",
    "        scoreList = self.search(searchlist, mode = mode)\n",
    "        for i in np.flip(np.argsort(scoreList))[:n]:\n",
    "            print( 'document:' , files[i],'score:', scoreList[i])\n",
    "        return np.flip(np.argsort(scoreList))[:n]\n",
    "            \n",
    "    def getFeedbackVector(self, searchList, top10results ,mode = 'cos'):\n",
    "        queryVector = self.buildQueryVector(searchList)\n",
    "        feedbackVector = self.buildQueryVector(top10results)\n",
    "        queryArray = np.array(queryVector)\n",
    "        feedbackArray = np.array(feedbackVector)\n",
    "        newQueryVector = list(queryArray + 0.5 * feedbackArray)\n",
    "        return newQueryVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72e6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "documents_chi = [] #0-499是英文檔案 ， 500-1500是中文檔案\n",
    "files_chi = []\n",
    "for file in os.listdir(\"./News/News\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        filename_chi = os.path.join(\"./News/News\", file)\n",
    "        files_chi.append(file[:-4])\n",
    "        with open(filename_chi, encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            doc = ' '.join(lines)\n",
    "            doc1 = doc.replace(\"\\n\", \"\")\n",
    "            documents_chi.append(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9a3b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(typedocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21bd51c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "files = []\n",
    "for file in os.listdir(\"./EnglishNews/EnglishNews\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        filename = os.path.join(\"./EnglishNews/EnglishNews\", file)\n",
    "        files.append(file[:-4])\n",
    "        with open(filename, encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            doc = ' '.join(lines)\n",
    "            doc1 = doc.replace(\"\\n\", \"\")\n",
    "            documents.append(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfca94dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\"Trump Biden Taiwan China\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a62d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:14<00:00, 495.89it/s]\n"
     ]
    }
   ],
   "source": [
    "vectorSpace_tf = VectorSpace(documents, 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a96060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7034/7034 [01:25<00:00, 82.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: News123256 score: 0.5163977794943223\n",
      "document: News119356 score: 0.5163977794943223\n",
      "document: News120265 score: 0.4685212856658182\n",
      "document: News108578 score: 0.4685212856658182\n",
      "document: News103117 score: 0.4287464628562721\n",
      "document: News115594 score: 0.42640143271122094\n",
      "document: News112667 score: 0.40089186286863665\n",
      "document: News122919 score: 0.4003203845127179\n",
      "document: News119746 score: 0.39528470752104733\n",
      "document: News101763 score: 0.39528470752104733\n",
      "document: News111959 score: 0.39528470752104733\n",
      "document: News115859 score: 0.39528470752104733\n",
      "document: News120085 score: 0.39043440472151514\n",
      "document: News122462 score: 0.39043440472151514\n",
      "document: News110775 score: 0.39043440472151514\n",
      "document: News112298 score: 0.39043440472151514\n",
      "document: News104498 score: 0.39043440472151514\n",
      "document: News107163 score: 0.38575837490522985\n",
      "document: News122750 score: 0.38575837490522985\n",
      "document: News114963 score: 0.38575837490522985\n",
      "document: News123385 score: 0.3768891807222046\n",
      "document: News111698 score: 0.3768891807222046\n",
      "document: News119485 score: 0.3768891807222046\n",
      "document: News115598 score: 0.3768891807222046\n",
      "document: News106911 score: 0.372677996249965\n",
      "document: News103873 score: 0.37267799624996495\n",
      "document: News115573 score: 0.37267799624996495\n",
      "document: News123360 score: 0.37267799624996495\n",
      "document: News107773 score: 0.37267799624996495\n",
      "document: News119460 score: 0.37267799624996495\n",
      "Term Frequency (TF) Weighting + Cosine Similarity\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7034/7034 [01:22<00:00, 85.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: News119356 score: 0.5163977794943223\n",
      "document: News123256 score: 0.5163977794943223\n",
      "document: News120265 score: 0.4685212856658182\n",
      "document: News108578 score: 0.4685212856658182\n",
      "document: News103117 score: 0.42874646285627216\n",
      "document: News115594 score: 0.42640143271122094\n",
      "document: News112667 score: 0.4008918628686366\n",
      "document: News122919 score: 0.4003203845127179\n",
      "document: News115859 score: 0.3952847075210474\n",
      "document: News119746 score: 0.3952847075210474\n",
      "document: News111959 score: 0.3952847075210474\n",
      "document: News101763 score: 0.3952847075210474\n",
      "document: News120085 score: 0.39043440472151514\n",
      "document: News104498 score: 0.39043440472151514\n",
      "document: News122462 score: 0.39043440472151514\n",
      "document: News110775 score: 0.39043440472151514\n",
      "document: News112298 score: 0.39043440472151514\n",
      "document: News107163 score: 0.3857583749052298\n",
      "document: News114963 score: 0.3857583749052298\n",
      "document: News122750 score: 0.3857583749052298\n",
      "document: News123385 score: 0.37688918072220456\n",
      "document: News119485 score: 0.37688918072220456\n",
      "document: News111698 score: 0.37688918072220456\n",
      "document: News115598 score: 0.37688918072220456\n",
      "document: News115573 score: 0.37267799624996495\n",
      "document: News106911 score: 0.37267799624996495\n",
      "document: News103873 score: 0.37267799624996495\n",
      "document: News123360 score: 0.37267799624996495\n",
      "document: News107773 score: 0.37267799624996495\n",
      "document: News119460 score: 0.37267799624996495\n",
      "Term Frequency (TF) Weighting + Euclidean Distance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rank_cos = vectorSpace_tf.printresult(query,files,30,'cos')\n",
    "print('Term Frequency (TF) Weighting + Cosine Similarity') #60% 前30: 100%\n",
    "print('-------------------------')\n",
    "rank_euc = vectorSpace_tf.printresult(query,files, 30,mode = 'eucli')\n",
    "print('Term Frequency (TF) Weighting + Euclidean Distance')#50% 前30: 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfaf6a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7034/7034 [20:15<00:00,  5.79it/s]\n"
     ]
    }
   ],
   "source": [
    "vectorSpace_tfidf = VectorSpace(documents,'tf-idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55429a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Weighting + Cosine Similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:58<00:00, 120.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: News103134 score: 0.47354915840176326\n",
      "document: News103767 score: 0.4560496763154008\n",
      "document: News116613 score: 0.4110554885255448\n",
      "document: News104913 score: 0.4110554885255448\n",
      "document: News108813 score: 0.4110554885255448\n",
      "document: News104914 score: 0.3894962370252556\n",
      "document: News112714 score: 0.3894962370252556\n",
      "document: News101014 score: 0.3894962370252556\n",
      "document: News116634 score: 0.38593749188632803\n",
      "document: News103728 score: 0.3649292024732102\n",
      "document: News103602 score: 0.32887988817071073\n",
      "document: News120085 score: 0.3149122389640781\n",
      "document: News104498 score: 0.3149122389640781\n",
      "document: News112298 score: 0.3149122389640781\n",
      "document: News110040 score: 0.3133693689239125\n",
      "document: News110441 score: 0.3111255372629767\n",
      "document: News106640 score: 0.3080687882294075\n",
      "document: News100757 score: 0.29709045391611855\n",
      "document: News110804 score: 0.29511422948403626\n",
      "document: News121995 score: 0.29225581198231654\n",
      "document: News118108 score: 0.29225581198231654\n",
      "document: News107830 score: 0.2876847733877949\n",
      "document: News105080 score: 0.2731988825469898\n",
      "document: News111015 score: 0.26557133629101504\n",
      "document: News101323 score: 0.2614508726801889\n",
      "document: News103117 score: 0.25722044674258376\n",
      "document: News103214 score: 0.256440764245066\n",
      "document: News101070 score: 0.22513438697757518\n",
      "document: News120265 score: 0.21909792943439116\n",
      "document: News108578 score: 0.21909792943439116\n",
      "TF-IDF Weighting + Euclidean Distance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7034/7034 [00:19<00:00, 352.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: News111696 score: 3.1738412094930877\n",
      "document: News108964 score: 3.090312939538556\n",
      "document: News107883 score: 3.0655439111104896\n",
      "document: News110141 score: 3.0640754366202367\n",
      "document: News122771 score: 3.014372604017926\n",
      "document: News110747 score: 3.009559318414031\n",
      "document: News108482 score: 2.934599696744801\n",
      "document: News108940 score: 2.9248801263833597\n",
      "document: News108270 score: 2.874122470395115\n",
      "document: News110871 score: 2.8523192991552713\n",
      "document: News107804 score: 2.829682742565021\n",
      "document: News107832 score: 2.8115392443751284\n",
      "document: News110833 score: 2.746581890623016\n",
      "document: News110401 score: 2.744118697256618\n",
      "document: News123304 score: 2.73874948545406\n",
      "document: News109473 score: 2.730692961761022\n",
      "document: News110223 score: 2.725498976409448\n",
      "document: News111034 score: 2.6819244734119745\n",
      "document: News109622 score: 2.66270152162418\n",
      "document: News123024 score: 2.6601117436200727\n",
      "document: News109912 score: 2.636160698408388\n",
      "document: News108024 score: 2.6299012784937372\n",
      "document: News110579 score: 2.6173442014973767\n",
      "document: News122495 score: 2.615172009658899\n",
      "document: News108062 score: 2.6111662541354987\n",
      "document: News109808 score: 2.60193091304006\n",
      "document: News119516 score: 2.5955984910339813\n",
      "document: News108334 score: 2.5714210285031593\n",
      "document: News110497 score: 2.55094239130443\n",
      "document: News110029 score: 2.550184663472354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('TF-IDF Weighting + Cosine Similarity') #70% #前30個100%\n",
    "rank_cos_tfidf = vectorSpace_tfidf.printresult(query,files, 30,'cos')\n",
    "print('TF-IDF Weighting + Euclidean Distance')#40% #前30個40%\n",
    "rank_euc_tfidf = vectorSpace_tfidf.printresult(query,files, 30,'eucli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c156e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "946e6dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Weighting + Cosine Similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7034/7034 [01:20<00:00, 87.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: News103134 score: 0.5197886511286802\n",
      "document: News104913 score: 0.5124974838557128\n",
      "document: News108813 score: 0.5124974838557128\n",
      "document: News116613 score: 0.5124974838557128\n",
      "document: News101014 score: 0.4989410742564866\n",
      "document: News112714 score: 0.4989410742564866\n",
      "document: News104914 score: 0.4989410742564866\n",
      "document: News103767 score: 0.49212543366673545\n",
      "document: News116634 score: 0.4379371826487922\n",
      "document: News103728 score: 0.3943061599242882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 754, 1168, 2183, 4360,  240, 3259, 1169,  900, 4368,  889],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "feedBack = []\n",
    "for i in rank_cos_tfidf:\n",
    "    feedBack.append(documents[i])\n",
    "    feedback = [\" \".join(feedBack)]\n",
    "\n",
    "print('TF-IDF Weighting + Cosine Similarity') # 70%\n",
    "newquery = vectorSpace_tfidf.getFeedbackVector(query, feedback, 'cos')\n",
    "vectorSpace_tfidf.printresult(newquery,files,'cos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daea5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c92602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "documents_chi = [] #0-499是英文檔案 ， 500-1500是中文檔案\n",
    "files_chi = []\n",
    "for file in os.listdir(\"./News/News\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        filename_chi = os.path.join(\"./News/News\", file)\n",
    "        files_chi.append(file[:-4])\n",
    "        with open(filename_chi, encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            doc = ' '.join(lines)\n",
    "            doc1 = doc.replace(\"\\n\", \"\")\n",
    "            documents_chi.append(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8722b633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(documents_chi[500:1500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37688ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f35890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d9a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b0f0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "22152a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: nan document: I haven't got a hat.\n",
      "score: nan document: Dogs and cats make good pets.\n",
      "score: nan document: A cat is a fine pet ponies.\n",
      "score: nan document: The cat cat in the hat disabled\n",
      "score: 1.2345525572306575 document: Dogs and cats make good pets.\n",
      "score: 1.0216002166437488 document: A cat is a fine pet ponies.\n",
      "score: 0.7504758415354574 document: The cat cat in the hat disabled\n",
      "score: 0.28768207245178085 document: I haven't got a hat.\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "\n",
    "documents = [\"The cat cat in the hat disabled\",\n",
    "                 \"A cat is a fine pet ponies.\",\n",
    "                 \"Dogs and cats make good pets.\",\n",
    "                 \"I haven't got a hat.\"]\n",
    "\n",
    "vectorSpace = VectorSpace(documents, 'tf-idf')  # vectorSpace(documents, vectorMode = 'tf' or 'tf-idf') (default is 'tf')\n",
    "\n",
    "\n",
    "#print(vectorSpace.vectorKeywordIndex)\n",
    "\n",
    "#print(vectorSpace.documentVectors)\n",
    "\n",
    "#print(vectorSpace.related(1))\n",
    "\n",
    "#print(vectorSpace.search([\"cat\"]))   \n",
    "\n",
    "vectorSpace.printresult([\"cat\"])\n",
    "vectorSpace.printresult([\"cat\"], mode = 'eucli')  # mode = 'cos' or 'eucli' (default is 'cos')\n",
    "\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179dc26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
