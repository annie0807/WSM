{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efc048e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from Parser import Parser\n",
    "import util\n",
    "from tfidf import *\n",
    "import glob, os\n",
    "import math\n",
    "import numpy as np\n",
    "import jieba\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "from __future__ import division, unicode_literals\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "class VectorSpace:\n",
    "    \"\"\" A algebraic model for representing text documents as vectors of identifiers. \n",
    "    A document is represented as a vector. Each dimension of the vector corresponds to a \n",
    "    separate term. If a term occurs in the document, then the value in the vector is non-zero.\n",
    "    \"\"\"\n",
    "\n",
    "    #Collection of document term vectors\n",
    "    documentVectors = []\n",
    "\n",
    "    #Mapping of vector index to keyword\n",
    "    vectorKeywordIndex = []\n",
    "    #vectorKeywordIndex_chi = []\n",
    "\n",
    "    #Tidies terms\n",
    "    parser=None\n",
    "    \n",
    "    def __init__(self, documents=[], vectorMode = 'tf'):\n",
    "        self.documentVectors=[]\n",
    "        self.parser = Parser()\n",
    "        self.BlobList = self.getBlobList(documents)\n",
    "        self.vectorMode = vectorMode\n",
    "        if(len(documents)>0):\n",
    "            self.build(documents)\n",
    "    \n",
    "    def getBlobList(self, documents): \n",
    "        bloblist = []\n",
    "        for doc in documents:\n",
    "            wordList = self.parser.tokenise(doc)\n",
    "            wordList = self.parser.removeStopWords(wordList)\n",
    "            bloblist.append(tb(\" \".join(wordList)))\n",
    "        return bloblist\n",
    "            \n",
    "    def build(self,documents):\n",
    "        \"\"\" Create the vector space for the passed document strings \"\"\"\n",
    "        self.vectorKeywordIndex = self.getVectorKeywordIndex(documents)\n",
    "        #print(self.vectorKeywordIndex_chi)\n",
    "        #self.vectorKeywordIndex_chi = self.getVectorKeywordIndex_chi(documents)\n",
    "        #print(self.vectorKeywordIndex_chi)\n",
    "        #self.vectorKeywordIndex = self.vectorKeywordIndex.update(self.vectorKeywordIndex_chi)\n",
    "        self.documentVectors = [self.makeVector(document, self.vectorMode) for document in tqdm(documents)]\n",
    "        \n",
    "    \n",
    "    def getVectorKeywordIndex_chi(self, documentList):\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def getVectorKeywordIndex(self, documentList):\n",
    "        \"\"\" create the keyword associated to the position of the elements within the document vectors \"\"\"\n",
    "\n",
    "        #Mapped documents into a single word string\t\n",
    "        vocabularyString = \" \".join(documentList)\n",
    "        print('把所有document連載一起 ',vocabularyString)\n",
    "        vocabularyList = self.parser.tokenise(vocabularyString) #斷詞\n",
    "        print('斷詞', vocabularyList)\n",
    "        #Remove common words which have no search value\n",
    "        vocabularyList = self.parser.removeStopWords(vocabularyList) # 去掉stop words\n",
    "        print('remove stop word', vocabularyList)\n",
    "        uniqueVocabularyList = util.removeDuplicates(vocabularyList) # 去掉重複詞\n",
    "        print('去掉重複詞', uniqueVocabularyList)\n",
    "        \n",
    "        vectorIndex={}\n",
    "        offset=0\n",
    "        #Associate a position with the keywords which maps to the dimension on the vector used to represent this word\n",
    "        for word in uniqueVocabularyList:\n",
    "            vectorIndex[word]=offset\n",
    "            offset+=1\n",
    "        return vectorIndex  #(keyword:position)\n",
    "\n",
    "\n",
    "    def makeVector(self, wordString, mode):\n",
    "        \"\"\" @pre: unique(vectorIndex) \"\"\"\n",
    "        #Initialise vector with 0's\n",
    "        vector = [0] * len(self.vectorKeywordIndex)\n",
    "        wordList = self.parser.tokenise(wordString)\n",
    "        wordList = self.parser.removeStopWords(wordList)\n",
    "        tbString = tb(\" \".join(wordList))\n",
    "        if mode == 'tf':\n",
    "            for word in list(set(wordList)):\n",
    "                vector[self.vectorKeywordIndex[word]] = tf(word, tbString) #Use simple Term Count Model\n",
    "            return vector \n",
    "        \n",
    "        if mode == 'tf-idf':\n",
    "            #print('bloblist:', self.BlobList)\n",
    "            for word in list(set(wordList)):\n",
    "                vector[self.vectorKeywordIndex[word]] =  tfidf(word, tbString , self.BlobList) \n",
    "            return vector\n",
    "        \n",
    "    def buildQueryVector(self, termList):\n",
    "        \"\"\" convert query string into a term vector \"\"\"\n",
    "        query = self.makeVector(\" \".join(termList), self.vectorMode)\n",
    "        return query\n",
    "\n",
    "    def related(self,documentId):\n",
    "        \"\"\" find documents that are related to the document indexed by passed Id within the document Vectors\"\"\"\n",
    "        ratings = [util.cosine(self.documentVectors[documentId], documentVector) for documentVector in self.documentVectors]\n",
    "        #ratings.sort(reverse=True)\n",
    "        return ratings\n",
    "    \n",
    "    def search(self,searchList, mode = 'cos'):\n",
    "        \"\"\" search for documents that match based on a list of terms \"\"\"\n",
    "        if type(searchList[0]) == str:\n",
    "            queryVector = self.buildQueryVector(searchList)\n",
    "        else:\n",
    "            queryVector = searchList\n",
    "        \n",
    "        if mode == 'cos':\n",
    "            ratings = [util.cosine(queryVector, documentVector) for documentVector in tqdm(self.documentVectors)]\n",
    "        #ratings.sort(reverse=True)\n",
    "            return ratings\n",
    "        if mode == 'eucli':\n",
    "            ratings = [util.Euclidean(queryVector, documentVector) for documentVector in tqdm(self.documentVectors)]\n",
    "            return ratings\n",
    "\n",
    "    def printresult(self,searchlist, files,n,mode='cos'):\n",
    "        scoreList = self.search(searchlist, mode = mode)\n",
    "        for i in np.flip(np.argsort(scoreList))[:n]:\n",
    "            print( 'document:' , files[i],'score:', scoreList[i])\n",
    "        return np.flip(np.argsort(scoreList))[:n]\n",
    "            \n",
    "    def getFeedbackVector(self, searchList, top10results ,mode = 'cos'):\n",
    "        queryVector = self.buildQueryVector(searchList)\n",
    "        feedbackVector = self.buildQueryVector(top10results)\n",
    "        queryArray = np.array(queryVector)\n",
    "        feedbackArray = np.array(feedbackVector)\n",
    "        newQueryVector = list(queryArray + 0.5 * feedbackArray)\n",
    "        return newQueryVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22152a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "把所有document連載一起  The cat cat in the hat disabled A cat is a fine pet ponies. Dogs and cats make good pets. I haven't got a hat.\n",
      "斷詞 ['the', 'cat', 'cat', 'in', 'the', 'hat', 'disabl', 'a', 'cat', 'is', 'a', 'fine', 'pet', 'poni', 'dog', 'and', 'cat', 'make', 'good', 'pet', 'i', \"haven't\", 'got', 'a', 'hat']\n",
      "remove stop word ['cat', 'cat', 'hat', 'disabl', 'cat', 'fine', 'pet', 'poni', 'dog', 'cat', 'make', 'good', 'pet', 'hat']\n",
      "去掉重複詞 {'make', 'hat', 'pet', 'poni', 'cat', 'disabl', 'dog', 'fine', 'good'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1914.11it/s]\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "\n",
    "documents = [\"The cat cat in the hat disabled\",\n",
    "                 \"A cat is a fine pet ponies.\",\n",
    "                 \"Dogs and cats make good pets.\",\n",
    "                 \"I haven't got a hat.\"]\n",
    "            #\"烏克蘭總統是澤倫斯基。\", \n",
    "            #\"澤倫斯基是親西方國家的烏克蘭總統，這讓普丁很不爽\"]\n",
    "\n",
    "vectorSpace = VectorSpace(documents, 'tf-idf')  # vectorSpace(documents, vectorMode = 'tf' or 'tf-idf') (default is 'tf')\n",
    "\n",
    "\n",
    "#print(vectorSpace.vectorKeywordIndex)\n",
    "\n",
    "#print(vectorSpace.documentVectors)\n",
    "\n",
    "#print(vectorSpace.related(1))\n",
    "\n",
    "#print(vectorSpace.search([\"cat\"]))   \n",
    "\n",
    "#vectorSpace.printresult([\"cat\"])\n",
    "#vectorSpace.printresult([\"cat\"], mode = 'eucli')  # mode = 'cos' or 'eucli' (default is 'cos')\n",
    "\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8fe927ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '--', '.', '..', '...', '......', '...................', './', '.一', '.數', '.日', '/', '//', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '://', '::', ';', '<', '=', '>', '>>', '?', '@', 'A', 'Lex', '[', ']', '^', '_', '`', 'exp', 'sub', 'sup', '|', '}', '~', '~~~~', '·', '×', '×××', 'Δ', 'Ψ', 'γ', 'μ', 'φ', 'φ．', 'В', '—', '——', '———', '‘', '’', '’‘', '“', '”', '”。', '…', '……', '…………………………………………………③', '′∈', '′｜', '℃', 'Ⅲ', '↑', '→', '∈［', '∪φ∈', '≈', '①', '②', '②ｃ', '③', '③］', '④', '⑤', '⑥', '⑦', '⑧', '⑨', '⑩', '──', '■', '▲', '、', '。', '〈', '〉', '《', '》', '》）。', '」', '『', '』', '【', '】', '〔', '〕', '〕〔', '㈧', '一', '一.', '一一', '一下', '一個', '一些', '一何', '一切', '一則', '一則通過', '一天', '一定', '一方面', '一旦', '一時', '一來', '一樣', '一次', '一片', '一番', '一直', '一致', '一般', '一起', '一轉眼', '一邊', '一面', '七', '萬一', '三', '三天兩頭', '三番兩次', '三番五次', '上', '上下', '上升', '上去', '上來', '上述', '上面', '下', '下列', '下去', '下來', '以下', '不', '不一', '不下', '不久', '不了', '不亦樂乎', '不僅', '不僅...並且', '不只', '不不過', '不會', '不但', '不但...並且', '不光', '不免', '不再', '不力', '不單', '不變', '不僅僅', '不可', '不可開交', '不可抗拒', '不同', '不外', '不外乎', '不夠', '不大', '不如', '最好還是', '不定', '不正確', '不少', '不盡', '不盡然', '不巧', '不已', '不常', '不得', '不得不', '不得了', '不得已', '不必', '不怎麽', '不怕', '不惟', '不成', '不拘', '不擇手段', '不敢', '不料', '不斷', '不日', '不時', '不是', '不曾', '不止', '不止一次', '不比', '不消', '不滿', '不然', '不然的話', '不特', '不獨', '不由得', '不知不覺', '無論', '無論如何', '不經意', '不勝', '不能', '不能不', '不至於', '不若', '不要', '不論', '不起', '不足', '只是', '不叠', '不問', '不限', '與', '與其', '與其說', '與否', '與此同一時候', '專門', '且', '且不說', '且說', '兩者', '嚴格', '嚴重', '個', '個人', '個別', '中小', '中間', '豐富', '串行', '臨', '臨到', '為', '為主', '為了', '為什麽', '為什麼', '為何', '為止', '為此', '為著', '主張', '主要', '舉凡', '舉行', '乃', '乃至', '乃至於', '麽', '之', '之中的一個', '之前', '之後', '之後', '之所以', '之類', '烏乎', '乎', '乒', '乘', '乘勢', '乘機', '乘勝', '乘虛', '乘隙', '九', '也', '也好', '也就是說', '也是', '也罷', '了', '了解', '爭取', '二', '二來', '二話不說', '二話沒說', '於', '於是', '於是乎', '雲雲', '雲爾', '互', '互相', '五', '些', '交口', '亦', '產生', '親口', '親手', '親眼', '親自', '親身', '人', '人人', '人們', '人家', '人民', '什麽', '什麽樣', '什麼', '僅', '只', '今', '今後', '今天', '今年', '今後', '介於', '仍', '仍舊', '仍然', '從', '從不', '從嚴', '從中', '從事', '從今以後', '從優', '從古到今', '從古至今', '從頭', '從寬', '從小', '從新', '從無到有', '從早到晚', '從未', '從來', '從此', '從此以後', '從而', '從輕', '從速', '從重', '他', '他人', '他們', '他是', '他的', '取代', '以', '以上', '下面', '以為', '以便', '以免', '曾經', '以及', '以後', '以外', '以後', '以故', '以期', '以來', '以至', '以至於', '以致', '們', '任', '不論什麽', '任憑', '任務', '企圖', '夥同', '會', '偉大', '傳', '傳說', '傳聞', '似乎', '似的', '但', '但凡', '但願', '可是', '何', '何樂而不為', '何以', '何況', '何處', '何妨', '何嘗', '何必', '何時', '何止', '何苦', '何須', '余外', '作為', '你', '你們', '你是', '你的', '使', '使得', '使用', '比如', '依', '根據', '按照', '依靠', '便', '便於', '促進', '保持', '保管', '保險', '俺', '俺們', '倍加', '倍感', '倒不如', '倒不如說', '倒是', '倘', '倘使', '倘或', '倘然', '倘若', '借', '借以', '借此', '假使', '假如', '假若', '偏偏', '做到', '偶爾', '偶而', '儻然', '像', '兒', '同意', '元／噸', '充其極', '充其量', '充分', '先不先', '先後', '先後', '先生', '光', '光是', '全體', '全力', '全年', '完全', '全身心', '所有', '全都', '全面', '八', '八成', '公然', '六', '兮', '共', '共同', '共總', '關於', '其', '其一', '當中', '其二', '其它', '其余', '其後', '其他', '事實上', '其次', '詳細', '詳細地說', '詳細來說', '詳細說來', '具有', '兼之', '內', '再', '再其次', '再則', '再有', '再次', '再者', '再者說', '再說', '冒', '沖', '決不', '決定', '決非', '況且', '準備', '湊巧', '凝神', '幾', '差點兒', '幾度', '幾時', '幾番', '幾經', '凡', '凡是', '憑', '憑借', '出', '出於', '出去', '出來', '出現', '分別', '分頭', '分期', '分期分批', '切', '切不可', '切切', '切勿', '切莫', '則', '則甚', '剛', '剛好', '剛巧', '剛才', '初', '別', '別人', '別處', '別是', '別的', '別管', '別說', '到', '到了兒', '到處', '到頭', '到頭來', '究竟', '到眼下為止', '前後', '前此', '前者', '前進', '前面', '加上', '加之', '加以', '增加', '加強', '動不動', '動輒', '勃然', '匆匆', '十分', '千', '千萬', '千萬千萬', '半', '單', '單單', '單純', '即', '即令', '即使', '即便', '即刻', '即如', '即將', '即或', '即是說', '即若', '卻', '卻不', '歷', '原來', '去', '又', '又及', '及', '及其', '及時', '及至', '兩方', '反之', '反之亦然', '反之則', '反倒', '反倒是', '反應', '反手', '反映', '反而', '反過來', '反過來說', '取得', '取道', '受到', '變成', '古來', '另', '還有一個', '還有一方面', '另外', '另悉', '另方面', '另行', '僅僅', '僅僅當', '僅僅怕', '僅僅是', '僅僅有', '僅僅消', '僅僅要', '僅僅限', '叫', '叫做', '召開', '叮咚', '叮當', '可', '能夠', '可好', '但是', '可能', '可見', '各', '各個', '各人', '各位', '各地', '各式', '各種', '各級', '各自', '合理', '同', '同一', '同一時候', '相同', '後', '後來', '後者', '後面', '向', '向使', '向著', '嚇', '嗎', '否則', '吧', '吧噠', '吱', '呀', '呃', '呆呆地', '吶', '嘔', '唄', '嗚', '嗚呼', '呢', '周圍', '呵', '呵呵', '呸', '呼哧', '呼啦', '咋', '和', '咚', '咦', '咧', '咱', '咱們', '咳', '哇', '哈', '哈哈', '哉', '哎', '哎呀', '哎喲', '嘩', '嘩啦', '喲', '哦', '哩', '哪', '哪個', '哪些', '哪兒', '哪天', '哪年', '哪怕', '哪樣', '哪邊', '哪裏', '哼', '哼唷', '唉', '唯有', '啊', '啊呀', '啊哈', '啊喲', '啐', '啥', '啦', '啪達', '啷當', '喀', '餵', '喏', '喔唷', '嘍', '嗡', '嗡嗡', '嗬', '嗯', '噯', '嘎', '嘎嘎', '嘎登', '噓', '嘛', '嘻', '嘿', '嘿嘿', '四', '因', '由於', '因了', '因此', '因著', '因而', '固', '固然', '在', '在下', '在於', '地', '均', '堅決', '堅持', '基於', '基本', '基本上', '處在', '處處', '處理', '復雜', '多', '多麽', '多虧', '多多', '多多少少', '多多益善', '多少', '多年前', '多年來', '多數', '多次', '夠瞧的', '大', '大不了', '大舉', '大事', '大體', '大體上', '大凡', '大力', '大多', '大多數', '大大', '大家', '大張旗鼓', '大批', '大抵', '大概', '大略', '大約', '大致', '大都', '大量', '大面兒上', '失去', '奇', '奈', '奮勇', '她', '她們', '她是', '她的', '好', '好在', '好的', '好象', '如', '如上', '如上所述', '例如以下', '現在', '怎樣', '如其', '如前所述', '如同', '如常', '如是', '如期', '假設', '如次', '如此', '如此等等', '如若', '始而', '姑且', '存在', '存心', '孰料', '孰知', '寧', '寧可', '寧願', '寧肯', '它', '它們', '它們的', '它是', '它的', '安全', '全然', '完畢', '定', '實現', '實際', '宣布', 'easy', '密切', '對', '對於', '相應', '對待', '對方', '對照', '將', '將才', '將要', '將近', '小', '少數', '爾', '爾後', '爾爾', '爾等', '尚且', '尤其', '就', '就地', '就是', '就是了', '就是說', '就此', '就算', '就要', '盡', '盡可能', '盡如人意', '盡心盡力', '盡心竭力', '盡快', '盡早', '盡然', '雖然', '雖然如此', '盡量', '局外', '竟然', '屆時', '屬於', '屢', '屢屢', '屢次', '屢次三番', '豈', '豈但', '豈止', '豈非', '川流不息', '左右', '巨大', '鞏固', '差一點', '差點兒相同', '己', '已', '已矣', '已經', '巴', '巴巴', '帶', '幫助', '常', '經常', '常言說', '常言說得好', '常言道', '平素', '年復一年', '並', '並不', '並非', '而且', '並排', '並無', '並沒', '並沒有', '並肩', '並不是', '廣大', '廣泛', '應當', '應用', '應該', '庶乎', '庶幾', '開外', '開始', '開展', '引起', '弗', '彈指之間', '強烈', '強調', '歸', '歸根究竟', '歸根結底', '歸齊', '當', '當下', '其中', '當兒', '當前', '當即', '當口兒', '當地', '當場', '當頭', '當庭', '當時', '當然', '當真', '當著', '形成', '徹夜', '徹底', '彼', '彼時', '彼此', '往', '往往', '待', '待到', '非常', '非常多', '非常少', '後來', '後面', '得', '得了', '得出', '得到', '得天獨厚', '得起', '心裏', '必', '必然', '必將', '必定', '必要', '必須', '快', '快要', '忽地', '忽然', '怎', '怎麽', '怎麽辦', '怎麽樣', '怎奈', '如何', '怎麼', '怕', '急匆匆', '怪', '怪不得', '總之', '總是', '總的來看', '總的來說', '總的說來', '總結', '總而言之', '恍然', '恐怕', '恰似', '恰好', '恰如', '恰巧', '恰恰', '恰恰相反', '恰逢', '您', '您們', '您是', '惟其', '慣常', '意思', '憤然', '願意', '慢說', '成為', '成年', '成年累月', '成心', '我', '我們', '我是', '我的', '或', '或則', '或多或少', '或是', '或曰', '或者', '也許', '戰鬥', '截然', '截至', '所', '所以', '所在', '所幸', '全部', '所謂', '才', '才幹', '撲通', '打', '打從', '打開天窗說亮話', '擴大', '把', '抑或', '抽冷子', '攔腰', '拿', '按', '按時', '按期', '依照', '按理', '按說', '挨個', '挨家挨戶', '挨次', '挨著', '挨門挨戶', '挨門逐戶', '換句話說', '換言之', '據', '據實', '據悉', '據我所知', '據此', '據稱', '據說', '掌握', '接下來', '接著', '接著', '接連不斷', '放量', '故', '有益', '故此', '故而', '敞開兒', '敢', '敢於', '敢情', '數/', '整個', '斷然', '方', '方便', '方才', '方能', '方面', '旁人', '無', '無寧', '無法', '不管', '既', '既...又', '既往', '既是', '既然', '日復一日', '日漸', '日益', '日臻', '日見', '時候', '昂然', '明顯', '明白', '是', '是不是', '是以', '是否', '是的', '顯然', '顯著', '普通', '普遍', '暗中', '暗地裏', '暗自', '更', '更為', '更加', '更進一步', '曾', '以前', '替', '替代', '最', '最後', '最大', '最好', '最後', '近期', '最高', '有', '有些', '有關', '有利', '有力', '有及', '有所', '有效', '有時', '有點', '有的', '有的是', '有著', '有著', '望', '朝', '朝著', '末##末', '本', '本人', '本地', '本著', '本身', '權時', '來', '來不及', '來得及', '來看', '來著', '來自', '來講', '來說', '極', '極為', '極了', '極其', '極力', '極大', '極度', '極端', '構成', '果然', '果真', '某', '某個', '某些', '某某', '依據', '根本', '格外', '梆', '概', '次第', '歡迎', '歟', '正值', '正在', '正如', '正巧', '正常', '正是', '此', '此中', '此後', '此地', '此處', '此外', '此時', '此次', '此間', '殆', '毋寧', '每', '每一個', '每天', '每年', '每當', '每時每刻', '每每', '每逢', '比', '比及', '比方', '比方說', '例如', '比照', '比起', '比較', '畢竟', '毫不', '毫無', '毫無例外', '毫無保留地', '汝', '沙沙', '沒', '沒奈何', '沒有', '沿', '沿著', '註意', '活', '深入', '清楚', '滿', '滿足', '漫說', '焉', '然', '然則', '然後', '然後', '然而', '照', '照著', '牢牢', '特別是', '特殊', '特點', '猶且', '猶自', '獨', '獨自', '猛然', '猛然間', '率爾', '率然', '現代', '如今', '理應', '理當', '理該', '瑟瑟', '甚且', '甚麽', '甚或', '甚而', '甚至', '甚至於', '用', '用來', '甫', '甭', '由', '因為', '由是', '由此', '由此可見', '略', '略為', '略加', '稍微', '白', '白白', '的', '的確', '的話', '皆可', '眼下', '直到', '直接', '類似', '相信', '相反', '同樣', '相對', '相對而言', '對應', '相當', '相等', '省得', '看', '看上去', '看出', '看到', '看來', '看樣子', '看看', '看見', '看起來', '真是', '真正', '眨眼', '著', '著呢', '矣', '矣乎', '矣哉', '知道', '砰', '確定', '碰巧', '社會主義', '離', '種', '積極', '移動', '到底', '窮年累月', '突出', '突然', '竊', '立', '立馬', '馬上', '立地', '立時', '立刻', '竟', '居然', '竟而', '第', '第二', '等', '等到', '等等', '策略地', '簡直', '簡而言之', '簡言之', '管', '類如', '粗', '精光', '緊接著', '累年', '累次', '純', '純粹', '縱', '縱令', '縱使', '縱然', '練習', '組成', '經', '常常', '經過', '結合', '結果', '給', '絕', '絕不', '絕對', '絕非', '絕頂', '繼之', '繼後', '繼續', '繼而', '維持', '綜上所述', '縷縷', '罷了', '老', '老大', '老是', '老老實實', '考慮', '者', '而', '並且', '而況', '而又', '而後', '而外', '而已', '而是', '而言', '而論', '聯系', '聯袂', '背地裏', '背靠背', '能', '是否能', '可以', '騰', '自', '自個兒', '自從', '自各兒', '自後', '自家', '自己', '自打', '自身', '臭', '至', '至於', '至今', '至若', '致', '般的', '良好', '若', '若夫', '若是', '若果', '若非', '範圍', '莫', '莫不', '莫不然', '莫如', '莫若', '莫非', '獲得', '藉以', '雖', '雖則', '盡管', '雖說', '蠻', '行為', '行動', '表明', '表示', '被', '要', '要不', '要不是', '要不然', '要麽', '要是', '要求', '見', '規定', '認為', '譬喻', '譬如', '覺得', '認真', '認識', '讓', '很多', '論', '論說', '設使', '設或', '設若', '誠如', '誠然', '話說', '該', '該當', '說明', '說來', '說說', '請勿', '諸', '諸位', '諸如', '誰', '誰人', '誰料', '誰知', '謹', '豁然', '賊死', '賴以', '趕', '趕快', '趕早不趕晚', '起', '起先', '起初', '起頭', '起來', '起見', '起首', '趁', '趁便', '趁勢', '趁早', '趁機', '趁熱', '趁著', '越是', '距', '跟', '路經', '轉動', '轉變', '轉貼', '轟然', '較', '較為', '較之', '較比', '邊', '達到', '達旦', '迄', '迅速', '過', '過於', '過去', '過來', '運用', '近', '近幾年來', '近年來', '近來', '還', '還是', '還有', '還要', '這', '這一來', '這個', '這麽', '這麽些', '這麽樣', '這麽點兒', '這些', '這會兒', '這兒', '這就是說', '這時', '這樣', '這次', '這點', '這樣的', '這般', '這邊', '這裏', '這麼', '進入', '進去', '進來', '進步', '進而', '進行', '連', '連同', '連聲', '連日', '連日來', '連袂', '連連', '遲早', '迫於', '適應', '適當', '適用', '逐步', '逐漸', '通常', '通過', '造成', '逢', '遇到', '遭到', '遵循', '遵照', '避免', '那', '那個', '那麽', '那麽些', '那麽樣', '那些', '那會兒', '那兒', '那時', '那末', '那樣', '那般', '那邊', '那裏', '那麼', '部分', '都', '鄙人', '採取', '裏面', '重大', '又一次', '重要', '鑒於', '針對', '長期以來', '長此下去', '長線', '長話短說', '問題', '間或', '防止', '阿', '附近', '陳年', '限制', '陡然', '除', '除了', '除卻', '除去', '除外', '除開', '除此', '除此之外', '除此以外', '除此而外', '除非', '隨', '隨後', '隨時', '隨著', '隨著', '隔夜', '隔日', '難得', '難怪', '難說', '難道', '難道說', '集中', '零', '須要', '非但', '很', '非徒', '非得', '非特', '非獨', '靠', '頂多', '頃', '頃刻', '頃刻之間', '頃刻間', '順', '順著', '頓時', '頗', '風雨無阻', '飽', '首先', '立即', '高低', '高興', '默然', '默默地', '齊', '︿', '！', '＃', '＄', '％', '＆', '＇', '（', '）', '）÷（１－', '）、', '＊', '＋', '＋ξ', '＋＋', '。', '。也', '－', '－β', '－－', '－［＊］－', '．', '／', '０', '０：２', '１', '１．', '１２％', '２', '２．３％', '３', '４', '５', '５：０', '６', '７', '８', '９', '：', '。', '＜', '＜±', '＜Δ', '＜λ', '＜φ', '＜＜', '＝', '＝″', '＝☆', '＝（', '＝－', '＝［', '＝｛', '＞', '＞λ', '？', '＠', 'Ａ', 'ＬＩ', 'Ｒ．Ｌ．', 'ＺＸＦＩＴＬ', '［', '［①①］', '［①②］', '［①③］', '［①④］', '［①⑤］', '［①⑥］', '［①⑦］', '［①⑧］', '［①⑨］', '［①Ａ］', '［①Ｂ］', '［①Ｃ］', '［①Ｄ］', '［①Ｅ］', '［①］', '［①ａ］', '［①ｃ］', '［①ｄ］', '［①ｅ］', '［①ｆ］', '［①ｇ］', '［①ｈ］', '［①ｉ］', '［①ｏ］', '［②', '［②①］', '［②②］', '［②③］', '［②④', '［②⑤］', '［②⑥］', '［②⑦］', '［②⑧］', '［②⑩］', '［②Ｂ］', '［②Ｇ］', '［②］', '［②ａ］', '［②ｂ］', '［②ｃ］', '［②ｄ］', '［②ｅ］', '［②ｆ］', '［②ｇ］', '［②ｈ］', '［②ｉ］', '［②ｊ］', '［③①］', '［③⑩］', '［③Ｆ］', '［③］', '［③ａ］', '［③ｂ］', '［③ｃ］', '［③ｄ］', '［③ｅ］', '［③ｇ］', '［③ｈ］', '［④］', '［④ａ］', '［④ｂ］', '［④ｃ］', '［④ｄ］', '［④ｅ］', '［⑤］', '［⑤］］', '［⑤ａ］', '［⑤ｂ］', '［⑤ｄ］', '［⑤ｅ］', '［⑤ｆ］', '［⑥］', '［⑦］', '［⑧］', '［⑨］', '［⑩］', '［＊］', '［－', '［］', '］', '］∧′＝［', '］［', '＿', 'ａ］', 'ｂ］', 'ｃ］', 'ｅ］', 'ｆ］', 'ｎｇ昉', '｛', '｛－', '｜', '｝', '｝＞', '～', '～±', '～＋', '￥']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nlines = f.readlines()\\ndoc = \\' \\'.join(lines)\\ndoc1 = doc.replace(\"\\n\", \"\")\\ndocuments_chi.append(doc1)'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChiStop = []\n",
    "with open('ChineseStopwords.txt', encoding=\"utf-8\") as f:\n",
    "    lines =f.readlines()\n",
    "    stop = ' '.join(lines)\n",
    "    ChiStop = stop.replace(\"\\n\", \"\").split()  \n",
    "print(ChiStop)    \n",
    "'''\n",
    "lines = f.readlines()\n",
    "doc = ' '.join(lines)\n",
    "doc1 = doc.replace(\"\\n\", \"\")\n",
    "documents_chi.append(doc1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01e96537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "烏克蘭總統是澤倫斯基。 澤倫斯基是親西方國家的烏克蘭總統，這讓普丁很不爽。\n",
      "['烏克蘭', '總統', '是澤倫斯基', '。', ' ', '澤倫斯', '基是親', '西方', '國家', '的', '烏克蘭', '總統', '，', '這讓', '普丁', '很', '不爽', '。']\n"
     ]
    }
   ],
   "source": [
    "documents_chi = [\"烏克蘭總統是澤倫斯基。\", \n",
    "            \"澤倫斯基是親西方國家的烏克蘭總統，這讓普丁很不爽。\"]\n",
    "vocabularyString = \" \".join(documents_chi)\n",
    "print(vocabularyString)\n",
    "vocabularyList = jieba.lcut_for_search(vocabularyString)\n",
    "    #vocabularyList.append(word)\n",
    "print(vocabularyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "395fb28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['烏克蘭', '總統', '是澤倫斯基', ' ', '澤倫斯', '基是親', '西方', '國家', '烏克蘭', '總統', '，', '這讓', '普丁', '不爽']\n",
      "{'總統', '是澤倫斯基', '，', '這讓', '基是親', '烏克蘭', '西方', '國家', '不爽', '澤倫斯', ' ', '普丁'}\n"
     ]
    }
   ],
   "source": [
    "vocabularyList  = [word for word in vocabularyList if word not in ChiStop ]\n",
    "print(vocabularyList)\n",
    "uniqueVocabularyList = set(vocabularyList)\n",
    "print(uniqueVocabularyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "84fdd090",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorIndex={}\n",
    "offset=0\n",
    "#Associate a position with the keywords which maps to the dimension on the vector used to represent this word\n",
    "for word in uniqueVocabularyList:\n",
    "    vectorIndex[word]=offset\n",
    "    offset+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a538d252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'總統': 0, '是澤倫斯基': 1, '，': 2, '這讓': 3, '基是親': 4, '烏克蘭': 5, '西方': 6, '國家': 7, '不爽': 8, '澤倫斯': 9, ' ': 10, '普丁': 11}\n"
     ]
    }
   ],
   "source": [
    "print(vectorIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3955c391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "烏克蘭總統是澤倫斯基。 澤倫斯基是親西方國家的烏克蘭總統，這讓普丁很不爽\n"
     ]
    }
   ],
   "source": [
    "vocabularyString = \" \".join(documents[4:])\n",
    "print(vocabularyString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e00c4385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12496/3309897751.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvectorSpace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVectorSpace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12496/2954207022.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, documents, vectorMode)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorMode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorMode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetBlobList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12496/2954207022.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorKeywordIndex_chi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetVectorKeywordIndex_chi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorKeywordIndex_chi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorKeywordIndex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorKeywordIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorKeywordIndex_chi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocumentVectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakeVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorMode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "vectorSpace = VectorSpace(documents, 'tf-idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0239c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "documents_chi = [] #0-499是英文檔案 ， 500-1500是中文檔案\n",
    "files_chi = []\n",
    "for file in os.listdir(\"./News/News\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        filename_chi = os.path.join(\"./News/News\", file)\n",
    "        files_chi.append(file[:-4])\n",
    "        with open(filename_chi, encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            doc = ' '.join(lines)\n",
    "            doc1 = doc.replace(\"\\n\", \"\")\n",
    "            documents_chi.append(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c92602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "documents_chi = [] #0-499是英文檔案 ， 500-1500是中文檔案\n",
    "files_chi = []\n",
    "for file in os.listdir(\"./News/News\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        filename_chi = os.path.join(\"./News/News\", file)\n",
    "        files_chi.append(file[:-4])\n",
    "        with open(filename_chi, encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            doc = ' '.join(lines)\n",
    "            doc1 = doc.replace(\"\\n\", \"\")\n",
    "            documents_chi.append(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8722b633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(documents_chi[500:1500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179dc26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
